# work12
早期的计算机使用7位的ASCII编码，为了处理汉字，程序员设计了用于简体中文的GB2312和用于繁体中文的big5。  GB2312(1980年)一共收录了7445个字符，包括6763个汉字和682个其它符号。汉字区的内码范围高字节从B0-F7，低字节从A1-FE，占用的码位是72*94=6768。其中有5个空位是D7FA-D7FE。  GB2312支持的汉字太少。1995年的汉字扩展规范GBK1.0收录了21886个符号，它分为汉字区和图形符号区。汉字区包括21003个字符。2000年的GB18030是取代GBK1.0的正式国家标准。该标准收录了27484个汉字，同时还收录了藏文、蒙文、维吾尔文等主要的少数民族文字。现在的PC平台必须支持GB18030，对嵌入式产品暂不作要求。所以手机、MP3一般只支持GB2312。  从ASCII、GB2312、GBK到GB18030，这些编码方法是向下兼容的，即同一个字符在这些方案中总是有相同的编码，后面的标准支持更多的字符。在这些编码中，英文和中文可以统一地处理。区分中文编码的方法是高字节的最高位不为0。按照程序员的称呼，GB2312、GBK到GB18030都属于双字节字符集 (DBCS)。  有的中文Windows的缺省内码还是GBK，可以通过GB18030升级包升级到GB18030。不过GB18030相对GBK增加的字符，普通人是很难用到的，通常我们还是用GBK指代中文Windows内码。  这里还有一些细节：  GB2312的原文还是区位码，从区位码到内码，需要在高字节和低字节上分别加上A0。  在DBCS中，GB内码的存储格式始终是big endian，即高位在前。  GB2312的两个字节的最高位都是1。但符合这个条件的码位128*128=16384个。所以GBK和GB18030的低字节最高位都可能不是1。不过这不影响DBCS字符流的解析：在读取DBCS字符流时，只要遇到高位为1的字节，就可以将下两个字节作为一个双字节编码，而不用管低字节的高位是什么。 前面提到从ASCII、GB2312、GBK到GB18030的编码方法是向下兼容的。而Unicode只与ASCII兼容（更准确地说，是与ISO-8859-1兼容），与GB码不兼容。例如“汉”字的Unicode编码是6C49，而GB码是BABA。  Unicode也是一种字符编码方法，不过它是由国际组织设计，可以容纳全世界所有语言文字的编码方案。Unicode的学名是"Universal Multiple-Octet Coded Character Set"，简称为UCS。UCS可以看作是"Unicode Character Set"的缩写。  根据维基百科全书(http://zh.wikipedia.org/wiki/)的记载：历史上存在两个试图独立设计Unicode的组织，即国际标准化组织（ISO）和一个软件制造商的协会（unicode.org）。ISO开发了ISO 10646项目，Unicode协会开发了Unicode项目。  在1991年前后，双方都认识到世界不需要两个不兼容的字符集。于是它们开始合并双方的工作成果，并为创立一个单一编码表而协同工作。从Unicode2.0开始，Unicode项目采用了与ISO 10646-1相同的字库和字码。  目前两个项目仍都存在，并独立地公布各自的标准。Unicode协会现在的最新版本是2005年的Unicode 4.1.0。ISO的最新标准是10646-3:2003。  UCS规定了怎么用多个字节表示各种文字。怎样传输这些编码，是由UTF(UCS Transformation Format)规范规定的，常见的UTF规范包括UTF-8、UTF-7、UTF-16。  IETF的RFC2781和RFC3629以RFC的一贯风格，清晰、明快又不失严谨地描述了UTF-16和UTF-8的编码方法。我总是记不得IETF是Internet Engineering Task Force的缩写。但IETF负责维护的RFC是Internet上一切规范的基础。  3、UCS-2、UCS-4、BMP  UCS有两种格式：UCS-2和UCS-4。顾名思义，UCS-2就是用两个字节编码，UCS-4就是用4个字节（实际上只用了31位，最高位必须为0）编码。下面让我们做一些简单的数学游戏：  UCS-2有2^16=65536个码位，UCS-4有2^31=2147483648个码位。  UCS-4根据最高位为0的最高字节分成2^7=128个group。每个group再根据次高字节分为256个plane。每个plane根据第3个字节分为256行 (rows)，每行包含256个cells。当然同一行的cells只是最后一个字节不同，其余都相同。  group 0的plane 0被称作Basic Multilingual Plane, 即BMP。或者说UCS-4中，高两个字节为0的码位被称作BMP。  将UCS-4的BMP去掉前面的两个零字节就得到了UCS-2。在UCS-2的两个字节前加上两个零字节，就得到了UCS-4的BMP。而目前的UCS-4规范中还没有任何字符被分配在BMP之外。  4、UTF编码  UTF-8就是以8位为单元对UCS进行编码。从UCS-2到UTF-8的编码方式如下：  UCS-2编码(16进制) UTF-8 字节流(二进制)  0000 - 007F 0xxxxxxx  0080 - 07FF 110xxxxx 10xxxxxx  0800 - FFFF 1110xxxx 10xxxxxx 10xxxxxx  例如“汉”字的Unicode编码是6C49。6C49在0800-FFFF之间，所以肯定要用3字节模板了：1110xxxx 10xxxxxx 10xxxxxx。将6C49写成二进制是：0110 110001 001001， 用这个比特流依次代替模板中的x，得到：11100110 10110001 10001001，即E6 B1 89。  读者可以用记事本测试一下我们的编码是否正确。  UTF-16以16位为单元对UCS进行编码。对于小于0x10000的UCS码，UTF-16编码就等于UCS码对应的16位无符号整数。对于不小于0x10000的UCS码，定义了一个算法。不过由于实际使用的UCS2，或者UCS4的BMP必然小于0x10000，所以就目前而言，可以认为UTF-16和UCS-2基本相同。但UCS-2只是一个编码方案，UTF-16却要用于实际的传输，所以就不得不考虑字节序的问题。  5、UTF的字节序和BOM  UTF-8以字节为编码单元，没有字节序的问题。UTF-16以两个字节为编码单元，在解释一个UTF-16文本前，首先要弄清楚每个编码单元的字节序。例如收到一个“奎”的Unicode编码是594E，“乙”的Unicode编码是4E59。如果我们收到UTF-16字节流“594E”，那么这是“奎”还是“乙”？  Unicode规范中推荐的标记字节顺序的方法是BOM。BOM不是“Bill Of Material”的BOM表，而是Byte Order Mark。BOM是一个有点小聪明的想法：  在UCS编码中有一个叫做"ZERO WIDTH NO-BREAK SPACE"的字符，它的编码是FEFF。而FFFE在UCS中是不存在的字符，所以不应该出现在实际传输中。UCS规范建议我们在传输字节流前，先传输字符"ZERO WIDTH NO-BREAK SPACE"。  这样如果接收者收到FEFF，就表明这个字节流是Big-Endian的；如果收到FFFE，就表明这个字节流是Little-Endian的。因此字符"ZERO WIDTH NO-BREAK SPACE"又被称作BOM。  UTF-8不需要BOM来表明字节顺序，但可以用BOM来表明编码方式。字符"ZERO WIDTH NO-BREAK SPACE"的UTF-8编码是EF BB BF（读者可以用我们前面介绍的编码方法验证一下）。所以如果接收者收到以EF BB BF开头的字节流，就知道这是UTF-8编码了。  Windows就是使用BOM来标记文本文件的编码方式的。  6、进一步的参考资料  本文主要参考的资料是 "Short overview of ISO-IEC 10646 and Unicode" (http://www.nada.kth.se/i18n/ucs/unicode-iso10646-oview.html)。  我还找了两篇看上去不错的资料，不过因为我开始的疑问都找到了答案，所以就没有看：  "Understanding Unicode A general introduction to the Unicode Standard" (http://scripts.sil.org/cms/scripts/page.php?site_id=nrsi&amp;item_id=IWS-Chapter04a)  "Character set encoding basics Understanding character set encodings and legacy encodings" (http://scripts.sil.org/cms/scripts/page.php?site_id=nrsi&amp;item_id=IWS-Chapter03)  我写过UTF-8、UCS-2、GBK相互转换的软件包，包括使用Windows API和不使用Windows API的版本。以后有时间的话，我会整理一下放到我的个人主页上(http://fmddlmyy.home4u.china.com/)。  Unicode,GBK,GB2312,UTF-8概念基础  本部分采用重用，转载一篇文章来完成这部分的目标。 来源：holen'blog   对字符编码与Unicode,ISO 10646,UCS,UTF8,UTF16,GBK,GB2312的理解 地址：http://blog.donews.com/holen/archive/2004/11/30/188182.aspx   Unicode:  unicode.org制定的编码机制, 要将全世界常用文字都函括进去. 在1.0中是16位编码, 由U+0000到U+FFFF. 每个2byte码对应一个字符; 在2.0开始抛弃了16位限制, 原来的16位作为基本位平面, 另外增加了16个位平面, 相当于20位编码, 编码范围0到0x10FFFF.    各个编码集的区别和适用范围 目前计算机中用得最广泛的字符集及其编码，是由美国国家标准局(ANSI)制定的ASCII码（American Standard Code for Information Interchange，美国标准信息交换码），它已被国际标准化组织（ISO）定为国际标准，称为ISO 646标准。适用于所有拉丁文字字母，ASCII码有7位码和8位码两种形式。      我们知道，在计算机内部，所有的信息最终都表示为一个二进制的字符串。每一个二进制位（bit）有0和1两种状态，因此八个二进制位就可以组合出256种状态，这被称为一个字节（byte）。也就是说，一个字节一共可以用来表示256种不同的状态，每一个状态对应一个符号，就是256个符号，从0000000到11111111。 英语用128个符号编码就够了，但是用来表示其他语言，128个符号是不够的。比如，在法语中，字母上方有注音符号，它就无法用ASCII码表示。于是，一些欧洲国家就决定，利用字节中闲置的最高位编入新的符号。比如，法语中的é的编码为130（二进制10000010）。这样一来，这些欧洲国家使用的编码体系，可以表示最多256个符号。 但是，这里又出现了新的问题。不同的国家有不同的字母，因此，哪怕它们都使用256个符号的编码方式，代表的字母却不一样。比如，130在法语编码中代表了é，在希伯来语编码中却代表了字母Gimel (ג)，在俄语编码中又会代表另一个符号。但是不管怎样，所有这些编码方式中，0—127表示的符号是一样的，不一样的只是128—255的这一段,所以出现后面的统一编码方式。 注:若想得到更详细的参见http://ascii.911cha.com/ 2、各地的方言 在中国，大陆最常用的就是GBK18030编码，除此之外还有GBK，GB2312，这几个编码的关系是这样的。  字符必须编码后才能被计算机处理。计算机使用的缺省编码方式就是计算机的内码。早期的计算机使用7位的ASCII编码，但为了处理汉字，又设计出用于简体中文的GB2312和用于繁体中文的big5。 GB2312(1980年)一共收录了7445个字符，包括6763个汉字和682个其它符号。汉字区的内码范围高字节从B0-F7，低字节从A1-FE，占用的码位是72*94=6768。其中有5个空位是D7FA-D7FE。 GB2312支持的汉字太少。1995年的汉字扩展规范GBK1.0收录了21886个符号，它分为汉字区和图形符号区。汉字区包括21003个字符。 从ASCII、GB2312到GBK，这些编码方法是向下兼容的，即同一个字符在这些方案中总是有相同的编码，后面的标准支持更多的字符。在这些编码中，英文和中文可以统一地处理。区分中文编码的方法是高字节的最高位不为0。按照程序员的称呼，GB2312、GBK都属于双字节字符集 (DBCS)。 2000年的GB18030是取代GBK1.0的正式国家标准。该标准收录了27484个汉字，同时还收录了藏文、蒙文、维吾尔文等主要的少数民族文字。从汉字字汇上说，GB18030在GB13000.1的20902个汉字的基础上增加了CJK扩展A的6582个汉字（Unicode码0x3400-0x4db5），一共收录了27484个汉字。 CJK就是中日韩的意思。Unicode为了节省码位，将中日韩三国语言中的文字统一编码。GB13000.1就是ISO/IEC 10646-1的中文版，相当于Unicode 1.1。 GB18030的编码采用单字节、双字节和4字节方案。其中单字节、双字节和GBK是完全兼容的。4字节编码的码位就是收录了CJK扩展A的6582个汉字。例如：UCS的0x3400在GB18030中的编码应该是8139EF30，UCS的0x3401在GB18030中的编码应该是8139EF31。 微软提供了GB18030的升级包，但这个升级包只是提供了一套支持CJK扩展A的6582个汉字的新字体：新宋体-18030，并不改变内码。Windows 的内码仍然是GBK。 也就是说Big5支持繁体中文，GB2312支持简体中文，Big5,GB2312是GBK的子集，GBK是GB18030的子集 日本：SJIS编码 注: 汉字编码简明对照表http://www.knowsky.com/resource/gb2312tbm.htm 3、GB2312 GB2312标准共收录6763个汉字，其中一级汉字3755个，二级汉字3008个；同时，GB2312收录了包括拉丁字母、希腊字母、日文平假名及片假名字母、俄罗斯语西里尔字母在内的682个全形字符。             GB2312的出现，基本满足了汉字的计算机处理需要，它所收录的汉字已经覆盖99.75%的使用频率。GB2312中对所收汉字进行了“分区”处理，每区含有94个汉字/符号。这种表示方式也称为区位码。            01-09区为特殊符号。            16-55区为一级汉字，按拼音排序。             56-87区为二级汉字，按部首/笔画排序。            10-15区及88-94区则未有编码。          举例来说，“啊”字是GB2312之中的第一个汉字，它的区位码就是1601。字节结构在使用GB2312的程序中，通常采用EUC储存方法，以便兼容于ASCII。每个汉字及符号以两个字节来表示。第一个字节称为“高位字节”，第二个字节称为“低位字节”。 “高位字节”使用了0xA1-0xF7(把01-87区的区号加上0xA0)，“低位字节”使用了0xA1-0xFE(把01-94加上0xA0)。例如“啊”字在大多数程序中，会以0xB0A1储存。（与区位码对比：0xB0=0xA0+16,0xA1=0xA0+1）。         所以GB2312编码中汉字区码的十进制是从176到247，位码是从161到255.之所以存储了6763小于82*94=6768，是因为在区码为215，位码为250-254之间共五个编码没有汉字编码，所以6768-5=6763个。   4、Unicode 如果把各种文字编码形容为各地的方言，那么Unicode就是世界各国合作开发的一种语言。 在这种语言环境下，不会再有语言的编码冲突，在同屏下，可以显示任何语言的内容，这就是Unicode的最大好处。 那么Unicode是如何编码的呢？其实非常简单。 就是将世界上所有的文字用２个字节统一进行编码。可能你会问，２个字节最多能够表示65536个编码，够用吗？ Unicode的学名是"Universal Multiple-Octet Coded Character Set"，简称为UCS。现在用的是UCS-2，即２个字节编码. 以现在的发展肯定是不够用得,如《康熙字典》收录了四万七千零三十五字，《汉语大字典》收录了五万六千多个。到目前为止，国际标准组织（ISO）制定国际标准时，共收集到汉字七万多字,所以出现UCS-4, 即4个字节编码，由原先的65536个编码扩展至将近100万编码。 注: 中日韩汉字Unicode编码表:http://www.chi2ko.com/tool/CJK.htm 查询需要Unicode编码的字符: http://www.unicode.org/charts/unihan.html http://www.nengcha.com/code/unicode/ 5、Unicode Big Endian和Little Endian 上面提到了一个字符可能占用多个字节，那么这多个字节在计算机中如何存储呢？比如字符0xabcd，它的存储格式到底是 AB CD，还是 CD AB 呢？ 实际上两者都有可能，并分别有不同的名字。如果存储为 AB CD，则称为Big Endian；如果存储为 CD AB，则称为Little Endian。 具体来说，以下这种存储格式为Big Endian，因为值(0xabcd)的高位(0xab)存储在前面： 地址 值  0x00000000 AB  0x00000001 CD  相反，以下这种存储格式为Little Endian： 地址 值  0x00000000 CD  0x00000001 AB  6、兼容codepage 那么既然统一了编码，如何兼容原先各国的文字编码呢？这个时候就需要codepage了。 什么是codepage？codepage就是各国的文字编码和Unicode之间的映射表。比如简体中文和Unicode的映射表就是CP936，点这里查看官方的映射表。 以下是几个常用的codepage，相应的修改上面的地址的数字即可。 codepage=936 简体中文GBK codepage=950 繁体中文BIG5 codepage=437 美国/加拿大英语 codepage=932 日文 codepage=949 韩文 codepage=866 俄文 codepage=65001 unicode UFT-8 从936中随意取一行，例如：0x9993 0x6ABD #CJK UNIFIED IDEOGRAPH.前面的编码是GBK的编码，后面的是Unicode。通过查这张表，就能简单的实现GBK和Unicode之间的转换 7、UTF-8 现在明白了Unicode，那么UTF-8又是什么呢？又为什么会出现UTF-8呢？ Unicode的最初目标，是用1个16位的编码来为超过65000字符提供映射。但这还不够，它不能覆盖全部历史上的文字，也不能解决传输的问题，尤其在那些基于网络的应用中。   因此，Unicode用一些基本的保留字符制定了三套编码方式。它们分别是UTF-8,UTF-16和UTF-32。正如名字所示，在UTF－8中，字符是以8位序列来编码的，用一个或几个字节来表示一个字符。这种方式的最大好处，是UTF－8保留了ASCII字符的编码做为它的一部分，例如，在UTF－8和ASCII中，“A”的编码都是0x41.  例:11100100 10111101 10100000à0xE4BDA0 “你”字的UTF-8编码 01001111 01100000        à0x4F60  “你”的Unicode编码 按照UTF-8的编码规则，11100100 10111101 10100000分解如下：xxxx0100 xx111101 xx100000,把除了x之外的数字拼接在一起，01001111 01100000就变成“你”的Unicode编码了.注意UTF-8的最前面３个1，表示整个UTF-8串是由３个字节构成的经过UTF-8编码之后，再也不会出现敏感字符了，因为最高位始终为1。 Unicode和UTF-8之间的转换关系表: 0000 0000-0000 007F | 0xxxxxxx 0000 0000-0080 07FF | 110xxxxx 10xxxxxx 0000 0800-0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx     0001 0000-0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx Unicode编码转换到UTF-8,简单的把Unicode字节流套到x中就变成UTF-8了。
